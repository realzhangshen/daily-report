"""
Core data types for the Daily Feed Agent.

This module defines the fundamental data structures used throughout the pipeline:
- Article: Raw article data parsed from markdown input
- ExtractedArticle: Article with fetched and extracted content
- AnalysisResult: Article with AI-generated open-ended analysis
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any


@dataclass
class Article:
    """Represents a raw article parsed from RSS feed markdown.

    Attributes:
        title: The article headline
        site: The website/publication name (e.g., "TechCrunch", "New York Times")
        url: The full URL to the original article
        time: Optional timestamp from the RSS feed
        author: Optional author name, extracted from source field if present
        summary: Optional brief summary from the RSS feed
        category: Optional category section this article belongs to
        id: Optional unique identifier from JSON input
        published_at: Optional ISO 8601 published timestamp from JSON input
        inserted_at: Optional ISO 8601 insertion timestamp from JSON input
    """
    title: str
    site: str
    url: str
    time: str | None = None
    author: str | None = None
    summary: str | None = None
    category: str | None = None
    id: str | None = None
    published_at: str | None = None
    inserted_at: str | None = None


@dataclass
class ExtractedArticle:
    """Article with fetched and extracted full text content.

    This represents an article after the fetch/extract stage of the pipeline.
    Either text or error will be populated, but not both.

    Attributes:
        article: The original Article object with metadata
        text: The extracted plain text content, or None if extraction failed
        error: Error message if fetch/extract failed, None otherwise
    """
    article: Article
    text: str | None
    error: str | None = None


@dataclass
class AnalysisResult:
    """Article with AI-generated open-ended analysis.

    This represents the output of the entry analysis stage, containing
    the original article and a long-form, unstructured analysis text.

    Attributes:
        article: The original Article object with metadata
        analysis: Long-form analysis text generated by the LLM
        status: Processing status - "ok", "analysis_only", "provider_error", "parse_error"
        meta: Additional metadata (e.g., model used, deep fetch decision)
    """
    article: Article
    analysis: str = ""
    status: str = "ok"
    meta: dict[str, Any] = field(default_factory=dict)


@dataclass
class ExtractionResult:
    """Structured metadata extracted from an article by Pass 1."""
    article: Article
    one_line_summary: str = ""
    category: str = ""
    tags: list[str] = field(default_factory=list)
    importance: int = 3
    content_type: str = ""
    key_takeaway: str = ""
    status: str = "ok"
    meta: dict[str, Any] = field(default_factory=dict)


@dataclass
class BriefingSection:
    """A themed section in the daily briefing."""
    theme: str
    description: str
    items: list[dict[str, Any]] = field(default_factory=list)


@dataclass
class BriefingResult:
    """Complete daily briefing produced by Pass 2 synthesis."""
    executive_summary: str = ""
    top_stories: list[dict[str, Any]] = field(default_factory=list)
    sections: list[BriefingSection] = field(default_factory=list)
    quick_mentions: list[dict[str, Any]] = field(default_factory=list)
    raw_text: str = ""
